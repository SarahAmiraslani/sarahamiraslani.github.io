<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Draw to Learn: A Strategy to Learn Abstract Concepts | Sarah H. Amiraslani </title> <meta name="author" content="Sarah H. Amiraslani"> <meta name="description" content="This project studies how student-generated drawings aid learning of abstract science concepts in a lab setting."> <meta name="keywords" content="portfolio-website, sarah-amiraslani, data-science, analytics, data, quantitative, portfolio"> <meta property="og:site_name" content="Sarah H. Amiraslani"> <meta property="og:type" content="website"> <meta property="og:title" content="Sarah H. Amiraslani | Draw to Learn: A Strategy to Learn Abstract Concepts"> <meta property="og:url" content="https://sarahamiraslani.github.io/projects/1_project/"> <meta property="og:description" content="This project studies how student-generated drawings aid learning of abstract science concepts in a lab setting."> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="Draw to Learn: A Strategy to Learn Abstract Concepts"> <meta name="twitter:description" content="This project studies how student-generated drawings aid learning of abstract science concepts in a lab setting."> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Sarah H. Amiraslani"
        },
        "url": "https://sarahamiraslani.github.io/projects/1_project/",
        "@type": "WebSite",
        "description": "This project studies how student-generated drawings aid learning of abstract science concepts in a lab setting.",
        "headline": "Draw to Learn: A Strategy to Learn Abstract Concepts",
        
        "sameAs": ["https://github.com/SarahAmiraslani", "https://www.linkedin.com/in/samirasl", "https://medium.com/@Sarah Amiraslani", "https://gitlab.com/SarahAmiraslani", "https://www.kaggle.com/sarahamiraslani7"],
        
        "name": "Sarah H. Amiraslani",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?ec6029d1e89ae2edc061ec9f0379d66d"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%A9%F0%9F%8F%BB%E2%80%8D%F0%9F%92%BB&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sarahamiraslani.github.io/projects/1_project/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Sarah</span> H. Amiraslani </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/resume/">Resume </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <d-front-matter> <script async type="text/json">
        {
            "title": "Draw to Learn: A Strategy to Learn Abstract Concepts",
            "description": "This project studies how student-generated drawings aid learning of abstract science concepts in a lab setting.",
            "published": "May 20, 2020",
            "code base": "https://github.com/SarahAmiraslani/drawing-to-learn",
            "authors": [
                
                {
                    "author": "Sarah Amiraslani",
                    "authorURL": "sarahamiraslani@gmail.com",
                    "affiliations": [
                        {
                            "name": "University of California - San Diego",
                            "url": ""
                        }
                    ]
                }
                
            ],
            "katex": {
                "delimiters": [
                    {
                        "left": "$",
                        "right": "$",
                        "display": false
                    },
                    {
                        "left": "$$",
                        "right": "$$",
                        "display": true
                    }
                ]
            }
        }
      </script> </d-front-matter> <div class="post distill"> <d-title> <h1>Draw to Learn: A Strategy to Learn Abstract Concepts</h1> <p>This project studies how student-generated drawings aid learning of abstract science concepts in a lab setting.</p> <p> <a href="https://github.com/SarahAmiraslani/drawing-to-learn" target="_blank" rel="noopener noreferrer" aria-label="GitHub Repository"> <svg height="32" width="32" viewbox="0 0 16 16" version="1.1" aria-hidden="true"> <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.58.82-2.14-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27s1.36.09 2 .27c1.53-1.03 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.14 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"> </path> </svg> </a> </p> </d-title> <d-byline> <p> <a href="sarahamiraslani@gmail.com">Sarah Amiraslani</a>, University of California - San Diego </p> </d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#summary">Summary</a> </div> <div> <a href="#introduction">Introduction</a> </div> <div> <a href="#methods">Methods</a> </div> <div> <a href="#results">Results</a> </div> <div> <a href="#discussion">Discussion</a> </div> <div> <a href="#acknowledgment">Acknowledgment</a> </div> </nav> </d-contents> <h1 id="summary">Summary</h1> <p>Have you ever wondered why images stick in your mind longer than words? Our brains are hardwired to process visual information with remarkable efficiency. Research shows that visual aids not only make learning easier by breaking down complex ideas, but also help illustrate spatial relationships, pinpoint knowledge gaps, and keep us captivated <d-cite key="mayer2008"></d-cite>. But what if drawing your own pictures could take learning to the next level, even more than instructor-provided visuals?</p> <p>Studies reveal that drawing can significantly enhance understanding of how physical systems work. However, its effectiveness hinges on factors like the accuracy of the drawings, the learner’s prior knowledge, and the level of guidance provided while drawing <d-cite key="fiorella2018"></d-cite>. Beginners often benefit from more structured support as creating accurate drawings from scratch is cognitively demanding and may detract from energy spent learning the material <d-cite key="vanmeter2005"></d-cite>. Yet, when dealing with content that doesn’t have a clear visual representation, the accuracy of these drawings may not be consequential. In these scenarios, student-generated drawings can capture their unique thought processes and create memorable visual representations.</p> <p>In two experiments, we randomly assigned college students to different learning tasks. Some studied or copied an instructor’s drawing, others completed a scaffolded drawing worksheet, and some drew their own representations on a blank sheet while reading about abstract concepts or physical systems. We found that, when it came to abstract lessons, unguided drawing significantly boosted retention but not transfer. However, for lessons on physical systems, drawing didn’t improve retention or transfer and students reported higher levels of intrinsic cognitive load.</p> <p>These insights suggest that while drawing aids learning, its impact depends on the nature of the content and the context in which it’s used. So next time you’re learning a new abstract concept, consider picking up a pen and sketching it out—you might just find it sticks with you longer. However, if you are learning about a physical system studying an instructor provided visual representation is preferred.</p> <h1 id="introduction">Introduction</h1> <p>Visual representations play a crucial role in learning by summarizing verbal information, illustrating spatial relationships, and enhancing memory retention <d-cite key="ainsworth2011"></d-cite>. While educational visuals are typically provided by instructors or the authors of textbooks, asking students to create their own drawings is less common <d-cite key="vanmeter2005"></d-cite>. Studying and constructing visuals engage different cognitive processes and can differentially impact learning <d-cite key="fiorella2018"></d-cite>. Therefore, it is essential to determine which method most effectively promotes meaningful learning.</p> <p>According to the Cognitive Theory of Multimedia Learning, effective learning involves selecting, organizing, and integrating new information with prior knowledge <d-cite key="mayer2002multimedia"></d-cite>. The more connections learners make between new material and their existing knowledge, the more likely they are to retain information and transfer it to new contexts <d-cite key="mayer2003nine"></d-cite>. Thus, an ideal learning strategy encourages the integration of new and prior knowledge.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/ctml-diagram-480.webp 480w,/assets/img/ctml-diagram-800.webp 800w,/assets/img/ctml-diagram-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/ctml-diagram.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Cognitive Theory of Multimedia Learning " loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> Figure 1. A visual representation of the Cognitive Theory of Multimedia Learning from Multimedia Learning <d-cite key="mayer2002multimedia"></d-cite>. While learning can occur through various media (e.g., text, podcasts, pictures), Multimedia Learning specifically involves processing both words and pictures. This distinction is important because verbal and pictorial information are processed through different cognitive pathways. </div> </div> <p>The Dual Channel Processing Theory, a well-supported cognitive theory, explains that we process verbal and non-verbal information through separate channels, forming unique connections between new material and our existing knowledge <d-cite key="paivio1968"></d-cite> . When learners draw, they engage both verbal and visual processing channels as process the text in a passage and create a corresponding visuospatial representation. This process enhances cognitive processing and recall <d-cite key="wammes2017learning"></d-cite>.</p> <p>Learner-generated drawings are visual representations created by students to achieve educational goals <d-cite key="alesandrini1981pictorial"></d-cite>. Generative learning strategies, like drawing, promote long-term understanding by helping learners identify gaps in their knowledge and update their understanding through self-monitoring <d-cite key="vanmeter2013"></d-cite>. Drawing allows students to personalize study materials, addressing individual differences in prior knowledge and learning needs. These drawings can be representational (faithfully depicting physical structures) or non-representational (abstract diagrams and flow charts) <d-cite key="carney2002pictorial"></d-cite>. Non-representational drawings may require additional cognitive processing to translate abstract visuals into meaningful content.</p> <p>Research on learner-generated drawings has yielded mixed results, influenced by factors such as prior knowledge and the level of guidance provided during the drawing process. Early studies showed weak effects favoring drawing to learn. For example, researchers found that drawing or paraphrasing while learning about electrochemistry had varied impacts based on the level of detail of students’ drawings <d-cite key="alesandrini1981pictorial"></d-cite>. Subsequent studies indicated that drawing without guidance might be too cognitively demanding, detracting from meaningful engagement with the material <d-cite key="schwamborn2011cognitive"></d-cite>. Guided drawing processes, such as providing drawing training or partially completed worksheets, have shown positive learning outcomes. These strategies help learners identify knowledge gaps, reduce cognitive load, and receive feedback on their mental representations <d-cite key="scheiter2017sketching"></d-cite>.</p> <h2 id="research-focus">Research Focus</h2> <p>Most studies on learner-generated drawings focus on concrete, observable systems. However, not all scientific concepts have definitive visual representations. Topics like dark matter, black holes, and natural selection are either theoretical, unfold over long periods, or lack a physical presence. Our research explores whether the efficacy of drawing to learn depends on the content of the lesson.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/previous-experiments-480.webp 480w,/assets/img/previous-experiments-800.webp 800w,/assets/img/previous-experiments-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/previous-experiments.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Previous Literature" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 2. Examples of lesson materials used in previous drawing to learn experiments. All of these studies teach students about physical systems that have a definitive physical representation. </div> <h2 id="hypothesis">Hypothesis</h2> <p>We hypothesize that drawing will enhance learning of abstract concepts more effectively than concrete ones. For abstract lessons, we expect learning to increase as students generate more of their own drawings. For concrete lessons, we predict that guided drawing will most benefit learning by reducing cognitive demands.</p> <h1 id="methods">Methods</h1> <h2 id="participants">Participants</h2> <p>A convenience sample of 238 undergraduate students was gathered from the University of California, San Diego Psychology Subject Pool. All participants received partial course credit for their participation. Twenty-five participants were excluded from data analysis, leaving a final sample of 213 participants. Of the 213 participants, 43 identified as male, 165 identified as female, and five identified as non-binary. A majority of participants were in their early twenties with a mean age of 20.27 (<em>SD</em> = 1.93 years). Fifty-seven students participated in the study condition, 54 in the copy condition, 54 in the complete condition, and 48 in the draw condition.</p> <h2 id="design">Design</h2> <p>We used a between-subjects design to manipulate participants’ drawing experience and measure their learning from a lesson about black holes. Participants were randomly assigned to one of four drawing conditions, which varied by the degree to which they generated their illustrations: copying a provided illustration (“copy”), completing a partial illustration (“complete”), free drawing their own illustration (“draw”), or a control condition that involved no drawing (“study”). Learning was measured using multiple choice and open response questions designed to assess both the retention and transfer of the lesson content. We also measured participants’ prior knowledge about physics and astronomy, their visual imagery ability, and their cognitive load during the learning activity to use as covariates in our analyses. The survey was designed to prevent participants from accessing the entire study at once or revisiting previous sections. While there was no time limit, participants were expected to complete the experiment within an hour.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/experimental-design-480.webp 480w,/assets/img/experimental-design-800.webp 800w,/assets/img/experimental-design-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/experimental-design.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Previous Literature" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 3. Visual representation of the experimental design. </div> <h2 id="materials">Materials</h2> <p>The materials for this study included a Qualtrics survey, a passage about black holes, illustrations to support the passage, passage comprehension tests (multiple choice and open response), and measures of individual differences (prior knowledge, visual imagery ability, cognitive load). All materials were presented to participants via a Qualtrics survey, which they accessed online via desktop computers in a lab setting.</p> <ul> <li> <p><strong>Prior Knowledge</strong>: Participants self-reported their knowledge and confidence in physics and astronomy using 5-point Likert scales. The knowledge scale ranged from “I know nothing at all” to “I know a great deal,” and the confidence scale ranged from “not confident at all” to “extremely confident.” The prior knowledge score was calculated by multiplying the knowledge and confidence ratings for both subjects and summing the results.</p> </li> <li> <p><strong>Black holes Lesson</strong>: All participants read an educational passage about black holes, adapted from The Cosmic Perspective textbook <d-cite key="bennett2016"></d-cite>. The passage was condensed to 11 paragraphs (1607 words) covering the definition, formation, properties, event horizon, singularity, size, and internal structure of black holes. The readability of the passage was measured using the Automated Readability Index (ARI), resulting in an ARI of 11.30, indicating a grade level of 11.6.</p> </li> <li> <p><strong>Illustrations</strong>: Participants in the copy, study, and complete conditions received illustrations produced using Adobe Photoshop 2019 and Pages. Inspired by The Cosmic Perspective textbook and Pearson Mastering Astronomy platform <d-cite key="pearson2019"></d-cite>, the illustrations included drawings of black hole features, Einstein’s Theory of General Relativity, and spacetime distortion near black holes. Scaffolded illustrations featured key elements masked with empty text boxes. Participants in the drawing condition received blank sheets of paper and pens.</p> </li> <li> <p><strong>Passage Comprehension Tests</strong>: Three types of tests were developed: two analogous 15-question multiple-choice tests, one 4-question open response retention test, and one 4-question open response transfer test. The multiple-choice tests included 8 perfect analogs and 7 strong pairs of questions. Retention questions asked students to summarize lesson information, while transfer questions required application of knowledge to new scenarios. Answers were scored based on identified idea units, with inter-rater reliability for retention and transfer tests being <em>r</em>(212)=0.995, <em>p</em> &lt;0.0001 and <em>r</em>(212)=0.798, <em>p</em> &lt;0.0001, respectively.</p> </li> <li> <p><strong>Cognitive Load</strong>: Cognitive load was measured using a 10-item instrument assessing intrinsic, extraneous, and germane load <d-cite key="leppink2013"></d-cite>. Participants rated items on a 0 to 10 scale. Examples included “The topics covered in the activity were very complex” (intrinsic load), “The instructions and explanations during the activity were very unclear” (extraneous load), and “The activity really enhanced my understanding of the topics covered” (germane load). Cognitive load was analyzed to determine the impact of visualization strategies on perceived difficulty and mental effort.</p> </li> <li> <p><strong>Visual Imagery</strong>: Visual imagery ability was assessed using the Vividness of Visual Imagery Questionnaire (VVIQ), which asks participants to rate the vividness of imagined scenes on a 5-point Likert scale <d-cite key="mckelvie1995"></d-cite>. The VVIQ was completed once with eyes open.</p> </li> </ul> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/copy-condition-experiment-480.webp 480w,/assets/img/copy-condition-experiment-800.webp 800w,/assets/img/copy-condition-experiment-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/copy-condition-experiment.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Experiment 1, Copy Condition" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> Figure 4. Example of completed copied drawings from the copy condition. Students assigned to this condition were given an instructor drawing to copy while reading the lesson. </div> </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/complete-condition-experiment-480.webp 480w,/assets/img/complete-condition-experiment-800.webp 800w,/assets/img/complete-condition-experiment-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/complete-condition-experiment.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Experiment 1, Complete Condition" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> Figure 5. Example of completed scaffolded drawings from the complete condition. Students assigned to this condition were asked to fill the blank rectangles to complete the visual representation of the learning material. </div> </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/draw-condition-experiment-480.webp 480w,/assets/img/draw-condition-experiment-800.webp 800w,/assets/img/draw-condition-experiment-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/draw-condition-experiment.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Experiment 1, Draw Condition" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> Figure 6. Example of completed learner-generated drawings from the draw condition. Students assigned to this condition were asked to generate their own visual representation of the learning materials. </div> </div> <h1 id="results">Results</h1> <h2 id="planned-analyses">Planned Analyses</h2> <p>The purpose of our experiment was to determine if more generative illustration activities would improve retention and transfer of knowledge about black holes. We hypothesized that participants who created their own illustrations would perform better on comprehension measures compared to those who studied provided illustrations. From the initial 238 participants, 213 were included in the final analysis after excluding those who did not engage in the illustration activity, failed attention checks, or did not complete the study.</p> <p>Participants demonstrated good visual imagery ability (<em>M</em> = 3.761, <em>SD</em> = 0.574) on a scale from 1 to 5, but reported low prior knowledge in physics and astronomy (<em>M</em> = 9.310, <em>SD</em> = 6.813) on a scale from 0 to 50. Their pre-test scores on a multiple-choice test specific to black holes were also low (<em>M</em> = 4.188 out of 12, <em>SD</em> = 1.963). There were no significant differences across conditions for visual imagery ability, self-reported prior knowledge, or pre-test scores, indicating a baseline similarity among participants.</p> <p>We analyzed the effects of illustration generativity on multiple-choice gains, open-response retention scores, and open-response transfer scores. No significant differences were found in multiple-choice gains or transfer scores across conditions. However, we did observe significant differences in open-response retention scores (<em>F</em>(3,209) = 7.41, <em>p</em> &lt; 0.001). Participants who drew their own illustrations (<em>M</em> = 6.688, <em>SD</em> = 2.93) scored significantly higher on retention compared to those who copied illustrations (<em>M</em> = 4.204, <em>SD</em> = 2.750, <em>p</em> &lt; 0.0001) and those who completed partial illustrations (<em>M</em> = 4.796, <em>SD</em> = 2.595, <em>p</em> = 0.0037). The difference between drawing and studying was near significance (<em>p</em> = 0.052).</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/mc-gain-480.webp 480w,/assets/img/mc-gain-800.webp 800w,/assets/img/mc-gain-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/mc-gain.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Multiple Choice Gain by Condition" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> Figure 7. A bar chart demonstrating participants’ multiple-choice gain (post-test minus pre-test) score. Higher scores indicate better performance and maximum possible gain score is 13. </div> </div> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/or-scores-480.webp 480w,/assets/img/or-scores-800.webp 800w,/assets/img/or-scores-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/or-scores.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Open Response Retention by Condition" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="caption"> Figure 8. A bar chart demonstrating participants’ performance on the open responses retention test organized by condition. Higher scores indicate better performance and the maximum possible score is 22. </div> </div> <h2 id="exploratory-analyses">Exploratory Analyses</h2> <p>Additional analyses were conducted to explore mechanisms by which drawing might enhance learning. We examined reading time, cognitive load, condition enjoyment, and word count:</p> <ul> <li> <p><strong>Reading Time</strong>: Participants in the drawing condition spent more time engaging with the lesson (<em>M</em> = 16.994 min, <em>SD</em> = 5.809) compared to other conditions (study, copy, complete), which could contribute to their better performance on the retention test. This was confirmed by a significant linear regression (<em>F</em>(1,211)=6.97, <em>p</em> = 0.008), with reading time predicting retention test scores.</p> </li> <li> <p><strong>Cognitive Load</strong>: We found no overall differences in cognitive load across conditions. However, significant differences were observed in extraneous load (<em>F</em>(3,209) = 15.82, <em>p</em> &lt; 0.0001) and germane load (<em>F</em>(3,209) = 6.20, <em>p</em> = 0.0005). Participants in the complete condition reported higher extraneous load, while those in the study condition reported higher germane load compared to other groups.</p> </li> <li> <p><strong>Condition Enjoyment</strong>: Participants in the study condition enjoyed the activity more (<em>M</em> = 3.965/5 Likert scale, <em>SD</em> = 0.778) than those in other conditions, with significant differences observed between study and complete conditions, and between copy and complete conditions.</p> </li> <li> <p><strong>Word Count</strong>: No significant differences were found in total word count or unique word count used to answer open response questions across conditions, suggesting that the amount of writing did not account for differences in retention scores.</p> </li> </ul> <h1 id="discussion">Discussion</h1> <p>The findings of our study suggest that drawing to learn theoretical science can enhance the recall of key points addressed in a passage. Participants in the drawing condition significantly outperformed all other groups on the open response retention test. However, they did not show superior performance on the multiple-choice test or the transfer test compared to other visualization conditions. The most notable difference in performance on the open response retention task was observed between the draw and copy conditions.</p> <p>These patterns of effects contradict previous findings that suggested students perform better on retention tests when their visualization is guided or inspired by an instructor. While our data indicate that the visualization strategy does not impact students’ transfer ability, it is possible that providing participants in future studies with more time could reveal an effect of visualization strategy. Additionally, exploratory analyses reveal that time spent on the passage may be a crucial factor in supporting retention performance and highlight that self-reported germane load is significantly predicted by the visualization condition.</p> <p>There are limitations to our study that future research should address. Importantly, a lab setting does not represent true learning environments where students are genuinely motivated to learn. Our participants were volunteers who participated to receive partial course credit, regardless of their performance in the experiment, which means they may not have been genuinely invested in learning about the formation and properties of black holes.</p> <p>Furthermore, certain visualization tasks may have disproportionately discouraged participants from completing the task. For example, because the study illustration condition requires no active engagement, participants assigned to this condition may have passively scanned the illustrations rather than studying them carefully. Similarly, students assigned to complete an illustration may have found this task odd or elementary, discouraging them from actively completing the worksheet. Feedback from our pilot study suggests that participants did not enjoy completing the illustration and were generally confused by it.</p> <p>Future studies should test these visualization manipulations in true classroom environments where theoretical science concepts are taught (e.g., advanced physics, astronomy, and evolutionary biology courses). This approach will help determine the effectiveness of drawing as a learning strategy in more realistic and motivating educational settings.</p> <h1 id="acknowledgments">Acknowledgments</h1> <p>This research was conducted at the University of California, San Diego in the <a href="https://www.lime-lab-ucsd.com" rel="external nofollow noopener" target="_blank">LIME Lab</a> between 2018 and 2020 and served as my honors thesis project. I would like to extend my heartfelt gratitude to Dr. Geller for providing invaluable mentorship and support throughout my time at UCSD. Your guidance was instrumental in the success of this project and my professional development.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/multimedia-learning-distill.bib"></d-bibliography> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"SarahAmiraslani/sarahamiraslani.github.io","data-repo-id":"R_kgDOL8JPNA","data-category":"General","data-category-id":"DIC_kwDOL8JPNM4CfaoA","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,a])=>giscusScript.setAttribute(t,a)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Sarah H. Amiraslani. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: July 22, 2024. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-PPKD31SS2Z"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-PPKD31SS2Z");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"Blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"Projects",description:"A growing collection of my favorite projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-repositories",title:"Repositories",description:"Selected code samples and GitHub statistics. For more detailed information, visit my Github profile.",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-resume",title:"Resume",description:"Below is a summary of my professional contributions, skills, and accomplishments. For portability and more detailed information, please click the pdf icon in the upper right to download my latest resume.",section:"Navigation",handler:()=>{window.location.href="/resume/"}},{id:"post-modeling-influence-in-networks",title:"Modeling Influence in Networks",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2024/modeling-influence-in-networks/"}},{id:"post-network-analysis-of-the-star-wars-films",title:"Network Analysis of the Star Wars Films",description:"an exploration of network analysis with networkx.",section:"Posts",handler:()=>{window.location.href="/blog/2024/starwars-network/"}},{id:"post-exploring-information-visualization-with-the-bechdel-test",title:"Exploring Information Visualization with the Bechdel Test",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2024/info-visualization-bechdel-test/"}},{id:"post-exploring-frequent-itemsets-using-tweets",title:"Exploring Frequent Itemsets using Tweets",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2024/itemsets-blog/"}},{id:"projects-draw-to-learn-a-strategy-to-learn-abstract-concepts",title:"Draw to Learn: A Strategy to Learn Abstract Concepts",description:"This project studies how student-generated drawings aid learning of abstract science concepts in a lab setting.",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-predicting-top-10-formula-1-finishes-and-clustering-race-tracks",title:"Predicting Top 10 Formula 1 Finishes and Clustering Race Tracks",description:"This project uses machine learning to predict top 10 finishes in F1 races and cluster tracks by characteristics.",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-predicting-sunspots",title:"Predicting Sunspots",description:"This project forecasts sunspots and HCS indexes using ensemble and deep learning to predict solar wind structure.",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-tracing-the-origins-of-solar-wind",title:"Tracing the Origins of Solar Wind",description:"This project uses machine learning to analyze solar wind, trace its solar corona origins, and predict heliophysical events.",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%73%61%72%61%68%61%6D%69%72%61%73%6C%61%6E%69@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/SarahAmiraslani","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/samirasl","_blank")}},{id:"socials-medium",title:"Medium",section:"Socials",handler:()=>{window.open("https://medium.com/@Sarah Amiraslani","_blank")}},{id:"socials-gitlab",title:"GitLab",section:"Socials",handler:()=>{window.open("https://gitlab.com/SarahAmiraslani","_blank")}},{id:"socials-kaggle",title:"Kaggle",section:"Socials",handler:()=>{window.open("https://www.kaggle.com/sarahamiraslani7","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> </body> </html>